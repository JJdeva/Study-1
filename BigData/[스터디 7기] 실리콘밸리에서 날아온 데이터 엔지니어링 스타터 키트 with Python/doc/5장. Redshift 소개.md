# Table of Contents

- [1. Data Warehouse Deep Dive](#1-data-warehouse-deep-dive)
- [2. Redshift Introduction](#2-redshift-introduction)
- [3. How to Access Redshift](#3-how-to-access-redshift)
- [4. Launch Redshift Cluster](#4-launch-redshift-cluster)
- [5. Lab Session and Assignment](#5-lab-session-and-assignment)

---

# 1. Data Warehouse Deep Dive

## A. Data Warehouse : a **separate** SQL database

- Still SQL is important and the most effective in handling structured data
	- Hive/SparkSQL/Presto
		- a proof that SQL is still the best
		- Good table schema design still matters
- Need to find the best option according to your situation
	- You can start small and it doesn't have to be a really scalable option from the beginning
	- As your data grows, switch to more scalable one
	- AWS Redshigt, Snowflake, Google Cloud BigQurey, Open source Hive/Spark/Presto
- Data Warehouse isn't your production database
	- It should be separated from your production database
	- OLAP (OnLine Analytical Processing) vs OLTP (OnLine Transaction Processing)

---

- DW는 별도의 SQL 관계형 데이터베이스임.
	- 구조화된 데이터를 다루는데 SQL만큼 편한게 없다.
	- BigQurey, Snowflake
		- price model이 돈을 쓴만큼 낸다.
		- Redshift보다 scalable함
	- Redshift
		- price model이 돈을 쓴만큼 내는 것과 고정비용 방식

- OLAP
	- Data Warehouse
	- 속도보다 데이터 크기가 중요함
		- 내부 직원들이 사용함
	- 별도의 내부 데이터 분석을 위한 DB라서 시간이 오래걸리건 데이터가 큰건 문제가 안됨.
- OLTP
	- production database
	- DB의 크기보다 속도가 중요하다.
		- 외부 사용자들의 행동을 기록하기 때문

## B. Central Data Storage of your Company

- Data Warehouse: the first step to become a “true” data organization
- Store raw data from different sources
- Create summary tables out of the raw data (and other summary)
	- Expose the summary tables to employees within the company
	- Being consistent is more important than being correct
- Fixed Cost option^[고정 비용 옵션] vs. Variable Cost Option^[쓴만큼 돈을 냄]
	- Variable cost option will provide decoupled capacity increase of storage and computation
		- BigQuery and Snowflake
	- Fixed cost option will give stable cost projection
		- Redshift or most on-premise data warehouse (open source based)

---

- DW는 회사의 중요한 데이터들이 다 저장되는 중앙 데이터 저장소
	- ETL을 통해서 raw data를 DW로 가져오게 됨.
	- raw data 중에 가장 중요한게 production database
		- production db에 기본적으로 우리 서비스를 사용하는 사용자들 OR 우리가 파는 상품 서비스의 정보가 들어가 있음
		- 따라서, 해당 정보를 DW에 복사해오는 것이 가장 중요한 ETL job이 된다.
	- data에 대한 abstract된 layer(summary tables)을 만들어야 함.
- Fixed Cost option
	- 고정 비용을 냄
	- DW를 사용하든 안하든 매달 정해진 비용을 냄.
- Variable Cost Option
	- 사용한만큼 돈을 냄
	- 따로 planning을 할 필요가 없음
	- 누가 실수하면, 돈이 엄청 청구될 수 있음.
	- 잘못짠 쿼리도 돌아갈 수도 있음
		- 쿼리를 더욱 잘 짜야함

# 2. Redshift Introduction

## A. Scalable SQL Engine in AWS

- Up to 2 PB of data in a cluster of servers
- Still OLAP
	- The response time won’t be in a sub-second
	- You shouldn’t use this in your customer facing service
- Columnar storage
	- Adding or dropping or renaming a column in a table is very fast
	- Per column compression is used
- Support bulk-update
	- Upload CSV/JSON files to S3 and copy from the S3 to Redshift
- Fixed Capacity SQL engine
	- vs. Snowflake vs. BigQuery
- Doesn’t guarantee primary key uniqueness!

---

- OLAP라서 속도가 느림
- Columnar storage
	- column by column storage임
- Support bulk-update
	- 자기들의 cloud storage에서 큰 파일을 한번에 DW의 테이블로 record 추가해줄 수 있음
- Fixed Capacity SQL engine
	- 기본적으로 Fixed Capacity
	- 최근에 Scalable option도 나옴
- Doesn't guarantee primary key uniqueness
	- pk를 지원안함
	- pk로 지정은 할 수 있는데, 그것을 system level에서 딱 하나의 record만 읽도록 보장해주지는 않음.
		- 이것을 보장하려면 record를 추가할때마다 체크해줘야함.
		- 그러면, 몇 천만개의 record를 추가하는 작업이 너무 오래걸림
	- DW에서 pk가 unique하다는 것을 보장해주는 것은 데이터 엔지니어의 책임임.

## B. Redshift is Postgresql 8.x compatible^[호환]

- But Redshift doesn’t support full features of Postgresql 8.x
- Accessible through most Postgresql 8.x clients/libraries
	- JDBC/ODBC
- SQL is the main language to interact
- Table schema design matters

---

- postgresql 8.x 버전과 호환이 됨
- postgresql이 access되는 language나 환경이면 다 사용 가능함.
- SQL이기 때문에 table design 중요함.

## C. Redshift Options and Pricing

![](/bin/DE7_image/DE7_5_1.png)

## D. Redshift Optimization can be tricky^[까다롭다]

- Distkey, Diststyle and Sortkey need to be optimized in 2+ Redshift cluster
	- distyle is to determine how distribution will be done
		- all, even, and key (default is “even”)
	- distkey is to determine which node to store a record
	- sortkey is to determine in what order to store records in a node
- A skewed table can cause a big performance issue

![](/bin/DE7_image/DE7_5_2.png)

---

- 서버 1개면 문제가 없는데, 서버 증설시 문제가 생김
- record가 추가될 때, 두 노드 중 어느 노드로 갈지 결정해야함.
- all
	- 두 노드에 매번 복사하여 중복해서 저장
- even
	- round robin하게 돌아가면서 저장
- distribution key
	- 테이블의 특정 필드의 값을 보고 그 값에 따라서 저장
	- dist key를 잘못 잡으면 90%는 Node 1에 저장되고 10%만 Node 2에 저장되는 경우가 생김
		- 나중에, 이 테이블을 가지고 Join을 할 때, skew^[빗나가다]가 생기면 엄청나게 오래 걸림.

> Redshift의 가장 큰 단점은 multi node로 갈 때, 개발자가 dist key를 관리해주어야 함.
> 똑같은 아키텍쳐로 되어 있음에도 snowflake나 big query는 개발자가 dist key를 몰라도 됨.
> > Snowflake나 big query는 다수의 node로 even하게 분산을 해줌
> > Redshift는 분산을 내가 해줘야함.

## E. Tightly Coupled with other AWS Services

- Seamless integration with the following services:
	- S3, EMR, [Kinesis](http://aws.amazon.com/kinesis/), DynamoDB, RDS and so on
- Supports Backup in S3
	- This is called snapshot. By default it will be in the same AWS region. Cross-regional snapshot is also supported
- Automatic resizing supported in newer bigger types

---

- AWS 내의 다른 기술들과 Integration^[통합]이 잘 되어 있음
- S3에 주기적으로 backup해줄 수 있음
	- backup을 snapshot이라 부름
	- snapshot으로부터 새로운 Redshift 클러스터를 쉽게 만들 수 있음.
- 클러스터 크기를 automatic resizing이 가능함.

## F. How to Extend Redshift Functionality?

- Python based UDF (User Defined Function) support
	- Python 2.x not Python 3
- Caching has been introduced since Dec 2017
- Redshift Spectrum
	- More Scalable version of DW to separate storage and computation
- S3 is used as the storage and on-demand Spark cluster is used as the computation layer

---

- 파이썬으로 함수를 짜서 Redshift SQL에서 지원해주는 기능이 부족한 경우 보강해줄 수 있음
- Redshift Spectrum
	- Redshift 바깥에서 Redshift에 데이터 적재를 큰 스케일로 해주는 기능
	- 내부적으로는 Spark로 구현되어 있음.

## G. Supported Data Type in RedShift

> PostgreSQL에서 지원하는 type들은 다 지원됨.

- SMALLINT (INT2)
- INTEGER (INT, INT4)
- BIGINT (INT8)
- DECIMAL (NUMERIC)
- REAL (FLOAT4)
- DOUBLE PRECISION (FLOAT8)
- BOOLEAN (BOOL)
- CHAR (CHARACTER)
- VARCHAR (CHARACTER VARYING)
- DATE
- TIMESTAMP

## H. Bulk Update Sequence - COPY SQL

내가 Redshift table에 굉장히 많은 수의 record를 추가해야 하는 경우, 그것을 하나하나 `INSERT INTO`하는 것이 아니라, 그것을 File로 만들어서 S3에 적재하고 COPY라는 SQL Command를 날리면 S3에 있는 File이 Redshift에 일괄 적재가 된다.

이 경우, 몇 천만개의 데이터를 추가하는데 몇 분만 걸리게 됨.

보통 이런 bulk up data를 cronjob이나 airflow같은 것으로 주기적으로 Data Source에서 data를 읽어다가 File로 만들어서 S3에 적재한 다음에 COPY를 하여 Redshift table로 한번에 복사한다.

이 기능은 Snowflake, BigQuery에서도 지원함.

![](/bin/DE7_image/DE7_5_3.png)

# 3. How to Access Redshift

> PostgreSQL을 접근할 수 있는 환경이면, 전부 Redshift에 접근할 수 있음

- 코딩을 하지 않는 관점
	- BI 툴을 통해 대시보드만 access
- 코딩을 하는 관점
	- PostgreSQL하고 호환되는 모듈들을 가져다가 코딩을 하면 된다.
	- Python에서는 psycopg2 모듈
- SQL client
	- [Postico (Mac)](https://eggerapps.at/postico/)
	- [SQL Workbench](https://docs.aws.amazon.com/redshift/latest/mgmt/connecting-using-workbench.html)
	- [DBeaver](https://dbeaver.io/)
	- [DataGrip](https://www.jetbrains.com/datagrip/) (JetBrain 사용중이라면 강추)
- Python Notebook

# 4. Launch Redshift Cluster

## A. Redshift Cluster Info

- 1 x dc2.large instance
	- 160 GB
- Host:
	- learnde.cduaw970ssvt.ap-northeast-2.redshift.amazonaws.com
- Port number:
	- 5439
- Database name:
	- dev

## B. Redshift Schema

Redshift cluster 밑에 dev라는 database가 있고 그 밑에 3개의 schema(raw_data, analytics, adhoc)가 있다.

- raw_data
	- 단순한 ETL들
	- 외부의 DB에서 데이터를 읽어서 그대로 DW에 적재되는 테이블들을 저장
- analytics
	- raw_data의 테이블을 통해 요약, JOIN 혹은 Extract하는 Summary Table을 저장
	- Dashboard를 만들거나 분석할 때는 raw_data보다는 analytics Schema에 있는 것만 사용한다.
- adhoc
	- 데이터 일을 하는 사람들이 table을 마음대로 만들어보는 등 개발을 하기 위한 놀이터

![](/bin/DE7_image/DE7_5_4.png)

## C. User and User Group Creation

사용자별로 permission을 관리하는 것은 어렵다.

기본적으로 Database에서 관리하는 제일 좋은 방법은 permission pattern에 맞춰서 group을 만들고, 그 group에 내가 원하는 permission을 주는 것이다. 그리고 사용자를 그 사용자에 맞는 group에 넣는다.

이렇게 하면, group만 관리하면 된다.

```sql

CREATE USER keeyong PASSWORD '...';

CREATE GROUP analytics_users;
GRANT USAGE ON SCHEMA analytics TO GROUP analytics_users;
GRANT USAGE ON SCHEMA raw_data TO GROUP analytics_users;
GRANT SELECT ON ALL TABLES IN SCHEMA analytics TO GROUP analytics_users;
GRANT SELECT ON ALL TABLES IN SCHEMA raw_data TO GROUP analytics_users;
GRANT ALL ON SCHEMA adhoc to GROUP analytics_users;
GRANT ALL ON ALL TABLES IN SCHEMA adhoc TO GROUP analytics_users;

ALTER GROUP analytics_users ADD USER keeyong;

```

# 5. Lab Session and Assignment

## A. 관계형 데이터베이스의 구조

- 관계형 데이터베이스는 2단계(혹은 3단계)로 구성됨
	- 가장 밑단에는 테이블들이 존재 (테이블은 엑셀의 시트에 해당)
	- 테이블들은 데이터베이스(혹은 스키마)라는 폴더 밑으로 구성

![](/bin/DE7_image/DE7_5_5.png)

## B. 테이블의 구조 (테이블 스키마라고 부르기도 함)

- 테이블은 레코드들로 구성
- 레코드는 하나 이상의 필드로 구성
- 필드는 이름과 타입으로 구성됨

![](/bin/DE7_image/DE7_5_6.png)

## C. 관계형 데이터베이스 예제

### a. 웹서비스 사용자/세션 정보

- 사용자 ID: 보통 웹서비스에서는 등록된 사용자마다 부여하는 유일한 ID
- 세션 ID: 세션마다 부여되는 ID
	- 세션: 사용자의 방문을 논리적인 단위로 나눈 것
		- 사용자가 외부 링크(보통 광고)를 타고 오거나 직접 방문해서 올 경우 세션을 생성
	- 즉 하나의 사용자는 여러 개의 세션을 가질 수 있음
	- 보통 세션의 경우 세션을 만들어낸 접점(경유지)를 채널이란 이름으로 기록해둠
		- 마케팅 관련 기여도 분석을 위함
	- 또한 세션이 생긴 시간도 기록
- 이 정보를 기반으로 다양한 데이터 분석과 지표 설정이 가능
	- 마케팅 관련, 사용자 트래픽 관련

![](/bin/DE7_image/DE7_5_7.png)

> visitor가 어떤 channel을 타고 우리 사이트를 방문했는지만 기록을 할 수 있으면, 마케터가 원하는 형태로 다양한 성능 분석이 가능하다.

- first channel attribution
	- 맨 처음 우리 사이트를 발견하게 해준 **channel**(Google)한테 모든 공을 넘김
- last channel attribution
	- 상품 구매와 같은 우리가 원하는 행동을 만들어준 맨 마지막 channel(naver)에 모든 공을 몰아줌
- Multi channel attribution
	- 상품 구매 과정에 있는 모든 channel한테 공을 나눠줌
	- 1/n로 공을 나눠주거나 / weight를 주어서 공을 나눠줌 

