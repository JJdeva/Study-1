# 0. 왜 파티셔닝을 사용해야 할까?

- 파티션 단위로 I/O 분산, 백업/복구가 가능하므로 대용량의 데이터를 핸들링 해야 할 때 DB 성능이 증가한다.
- 데이터의 물리적 형상이 분리되기 때문에 데이터가 한 번에 손실 될 가능성이 적다.

# 6. 파티셔닝

![](/bin/DDIA_image/Designing_Data_intensive_6_1.png)

- Horizontal Partitioning
	- 데이터 개수를 기준으로 나누어 Partitioning 하는 방법
	- 스키마가 같은 데이터를 두 개 이상의 테이블에 나누어 저장하는 디자인.
- Vertical Partitioning
	- 테이블의 칼럼을 기준으로 Partitioning 하는 방법
	- 스키마가 분할 된다.

---

- 샤딩 (Sharding)
	- 데이터셋이 매우 크거나 질의 처리량이 매우 높다면 복제만으로는 부족하고 데이터를 **파티션**으로 쪼개는 작업
	- **물리적으로 다른 데이터베이스**에 데이터를 수평 분할 방식으로 분산 저장하고 조회하는 방법.
	- 대용량 데이터베이스를 의도적으로 작은 단위로 쪼개는 방법

```

파티션 = 샤드(shard) = 리전(region) = 태블릿(tablet) = 브이노드(vnode) = 브이버켓(vBucket)

- 샤드(shard)
	- 몽고DB, 엘라스틱서치, 솔라클라우드
- 리전(region)
	- HBase
- 태블릿 (tablet)
	- 빅테이블
- 브이노드 (vnode)
	- 카산드라, 리악
- 브이버켓 (vBucket)
	- 카우치베이스

```

 파티션을 나눌 때는 보통 각 데이터 단위(레코드, 로우, 문서)가 하나의 파티션에 속하게 된다.  
데이터베이스가 여러 파티션을 동시에 건드리는 연산을 지원할 수도 있지만 결과적으로 각 파티션은 그 자체로 작은 데이터베이스가 된다.

데이터 파티셔닝을 원하는 주된 이유는 **확장성**이다. 비공유 클러스터(shared-nothing cluster)에서 다른 파티션은 다른 노드에 저장될 수 있다. 따라서 대용량 데이터셋이 여러 디스크에 분산될 수 있고 질의 부하는 여러 프로세서에 분산될 수 있다.

![](/bin/DDIA_image/Designing_Data_intensive_6_2.png)

각 노드에서 자신의 파티션에 해당하는 질의를 독립적으로 실행할 수 있으므로 노드를 추가함으로써 질의 처리량을 늘릴 수 있다. 크고 복잡한 질의는 훨씬 더 어렵기는 하지만 여러 노드에서 병렬 실행이 가능하다.

![](/bin/DDIA_image/Designing_Data_intensive_6_3.png)

파티셔닝의 기본 원칙은 OLAP, OLTP 두 종류의 작업부하에 모두 적용된다.

## A. 파티셔닝과 복제

보통 복제와 파티셔닝을 함께 적용해 각 파티션의 복사본을 여러 노드에 저장한다. 각 레코드는 정확히 한 파티션에 속하더라도 이를 여러 다른 노드에 저장해서 내결함성을 보장할 수 있다는 의미다.

> 내결함성
> 시스템의 일부 구성 요소가 작동하지 않더라도 계속 작동할 수 있는 기능

한 노드에 여러 파티션을 저장할 수도 있다. 각 파티션의 리더는 하나의 노드에 할당되고 팔로워들은 다른 노드에 할당된다. 각 노드는 어떤 파티션에게는 리더이면서 다른 파티션에게는 팔로워가 될 수 있다.

데이터베이스 복제에 관한 모든 내용은 파티션의 복제에도 동일하게 적용된다. 일반적으로 파티셔닝 방식과 복제 방식은 독립적으로 선택한다.

![](/bin/DDIA_image/Designing_Data_intensive_6_4.png)

## B. 키-값 데이터 파티셔닝 (Partitioning of Key-Value Data)

파티셔닝의 목적은 데이터와 질의 부하를 노드 사이에 고르게 분산시키는 것이다. 모든 노드가 동일한 분량을 담당한다고 가정할 때 10대의 노드를 사용하면 한 대를 사용할 때보다 이론상으로 10배의 데이터를 저장하고 10배의 읽기, 쓰기 요청을 처리할 수 있다.

![](/bin/DDIA_image/Designing_Data_intensive_6_5.png)

다른 파티션보다 데이터가 많거나 질의를 많이 받는 파티션이 있다면 **쏠렸다(skewed)** 고 말한다. 쏠림이 있으면 파티셔닝의 효과가 매우 떨어진다. 극단적인 경우 모든 부하가 한 파티션에 몰려 10개 중 9개 노드는 유휴 상태에 있고 요청을 받는 노드 하나가 병목이 될 수 있다. 불균형하게 부하가 높은 파티션을 **핫스팟**이라고 한다.

![](/bin/DDIA_image/Designing_Data_intensive_6_6.png)

핫스팟을 회피하는 가장 단순한 방법은 레코드를 할당한 노드를 무작위로 선택하는 것이다. 어떤 레코드를 읽으려고 할 때 해당 레코드가 어느 노드에 저장됐는지 알 수 없으므로 모든 노드에서 병렬적으로 질의를 실행해야 한다.

단순한 키-값 데이터 모델에서는 항상 키본키를 통해 레코드에 접근한다.

### a. 키 범위 기준 파티셔닝 (Partitioning by Key Range)

각 파티션에 연속된 범위의 키를 할당하는 것이다. 각 범위들 사이의 경계를 알면 어떤 키가 어느 파티션에 속하는지 쉽게 찾을 수 있다. 또 어떤 파티션이 어느 노드에 할당됐는지 알면 적절한 노드로 요청을 직접 보낼 수 있다.

![](/bin/DDIA_image/Designing_Data_intensive_6_7.png)

키 범위 크기가 반드시 동일한 필요는 없다. 데이터가 고르게 분포하지 않을 수도 있기 때문이다. 데이터를 고르게 분산시키려면 파티션 경계를 데이터에 맞춰 조정해야 한다.

파티션 경계는 관리자가 수동으로 선택하거나 데이터베이스에서 자동으로 선택되게 할 수 있다. 이런 식으로 파티셔닝하는 전략은 빅테이블, 빅테이블의 오픈소스 구현체인 HBase, 리싱크DB (RethinkDB), 버전 2.4 이전의 몽고DB에서 사용된다.

각 파티션 내에서는 키를 정렬된 순서로 저장할 수 있다. 이렇게 하면 범위 스캔(range scan: BETWEEN A AND B)이 쉬워지는 이점이 있고, 키를 연쇄된 색인(Index)으로 간주해서 질의 하나로 관련 레코드 여러 개를 읽어오는 데 사용할 수 있다.

#### ㄱ. 키 범위 기준 파티셔닝의 단점

키 범위 기준 파티셔닝은 특정한 접근 패턴이 핫스팟을 유발하는 단점이 있다. 예를 들어 1일치의 데이터를 파티션 하나가 담당하는 식이면, 센서에서 값이 측정될 때마다 데이터를 데이터베이스에 기록하므로 쓰기 연산이 모두 동일한 파티션으로 전달되어 해당 파티션만 과부하가 걸리고 나머지 파티션은 유휴 상태로 남아 있을 수 있다.

이 문제를 회피하려면 키의 첫 번째 요소로 타임스탬프가 아닌 다른 것을 사용해야 한다. 파티셔닝할 때 센서 이름을 먼저 사용한 후 시간을 사용하게 할 수 있다. 동시에 동작하는 센서가 많이 있다면 쓰기 부하가 파티션 사이에 더 균등하게 퍼진다.

![](/bin/DDIA_image/Designing_Data_intensive_6_8.png)

### b. 키의 해시값 기준 파티셔닝 (Partitioning  by Hash of Key)

쏠림과 핫스팟의 위험 때문에 많은 분산 데이터스토어는 키의 파티션을 정하는 데 해시 함수를 사용한다.

좋은 해시 함수는 쏠린 데이터를 입력으로 받아 균일하게 분산되게 한다.

![](/bin/DDIA_image/Designing_Data_intensive_6_9.png)

파티셔닝용 해시 함수는 암호적으로 강력할 필요는 없다. 카산드라와 몽고DB는 MD5를 쓰고 볼트모트는 파울러 놀 보(Fowler-Noll-Vo) 함수를 사용한다. 많은 프로그래밍 언어에 간단한 해시 함수가 내장돼 있지만 파티셔닝에는 적합하지 않을지도 모른다. 예를 들어 자바의 `Object.hashCode()`와 루비의 `Object#hash`는 같은 키를 넣어도 다른 프로세스에서는 다른 해시값을 반환할 수 있다.

키에 적합한 해시 함수를 구했다면 각 파티션에 해시값 범위를 할당하고 해시값이 파티션의 범위에 속하는 모든 키를 그 파티션에 할당하면 된다.

이 기법은 키를 파티션 사이에 균일하게 분산시키는 데 좋다. 파티션 경계는 크기가 동일하도록 나눌 수도 있고 무작위에 가깝게 선택할 수도 있다. (이런 기법을 **일관성 해싱**이라고 부르기도 한다.)

```

일관성 해싱 (Consistent Hashing)

CDN (content delivery network) 같은 인터넷 규모의 캐시 시스템에서 부하를 균등하게 분산시키는 방법이다. 중앙 제어나 분산 합의(distributed consensus)가 필요하지 않도록 파티션 경계를 무작위로 선택한다.

특별한 재균형화 방법을 의미한다.

이 특별한 방법은 데이터베이스에서 실제로는 잘 동작하지 않아서, 현실에서는 거의 사용되지 않는다.

```

#### ㄱ. 키의 해시값 기준 파티셔닝의 단점

파티셔닝에 키의 해시값을 사용해서 파티셔닝하면 범위 질의를 효율적으로 실행할 수 있는 키 범위 파티셔닝의 좋은 속성을 잃어 버린다. 전에는 인접했던 키들이 이제는 모든 파티션에 흩어져서 정렬 순서가 유지되지 않는다. 몽고DB에서는 해시 기반 샤딩 모드를 활성화하면 범위 질의가 모든 파티션에 전송돼야 한다. 리악, 카우치베이스, 볼드모트에서는 기본키에 대한 범위 질의가 지원되지 않는다.

카산드라는 두 가지 파티셔닝 전략 사이에서 타협한다. 카산드라에서 테이블을 선언할 때 여러 칼럼을 포함하는 **복합 기본키 (compound primary key)** 를 지정할 수 있다. 키의 첫 부분에만 해싱을 적용해 파티션 결정에 사용하고 남은 칼럼은 카산드라의 SS테이블에서 데이터를 정렬하는 연쇄된 색인(Index)으로 사용한다. 첫 번째 칼럼에 고정된 값을 지정하면 키의 다른 칼럼에 대해서는 범위 스캔을 효율적으로 실행할 수 있다.

연쇄된 색인(Index)을 사용하면 일대다 관계를 표현하는 우아한 데이터 모델을 만들 수 있다.

### c. 쏠린 작업부하와 핫스팟 완화

키를 해싱해서 파티션을 정하면 핫스팟을 줄이는 데 도움이 된다. 그렇지만 핫스팟을 완벽히 제거할 수는 없다. 항상 동일한 키를 읽고 쓰는 극단적인 상황에서는 모든 요청이 동일한 파티션으로 쏠리게 된다.

현대 데이터 시스템은 대부분 크게 쏠린 작업부하를 자동으로 보정하지 못하므로 애플리케이션에서 쏠림을 완화해야 한다. 예를 들어 요청이 매우 많이 쏠리는 키를 발견했을 때 간단한 해결책은 각 키의 시작이나 끝에 임의의 숫자를 붙이는 것이다.

![](/bin/DDIA_image/Designing_Data_intensive_6_10.png)

다른 키에 쪼개서 쓰면 읽기를 실행할 때 추가적인 작업이 필요해진다. 따라서 이 기법은 요청이 몰리는 소수의 키에만 적용하는 게 타당하다. 쓰기 처리량이 낮은 대다수의 키에도 적용하면 불필요한 오버헤드가 생긴다. 따라서 어떤 키가 쪼개졌는지 추적할 방법도 있어야 한다.

## C. 파티셔닝과 보조 색인 (Secondary Indexes)

보조 색인 (Secondary Indexes)은 보통 레코드를 유일하게 식별하는 용도가 아니라 특정한 값이 발생한 항목을 검색하는 수단이다.

보조 색인 (Secondary Indexes)은 관계형 데이터베이스의 핵심 요소이며 문서 데이터베이스에서도 흔하다. 많은 키-값 저장소(key-value store)에서는 구현 복잡도가 추가되는 것을 피하려고 보조 색인 (Secondary Indexes)을 지원하지 않지만 보조 색인 (Secondary Indexes)은 데이터 모델링에 매우 유용하므로 일부 저장소(리악)에서는 이를 추가하기 시작했다. 그리고 마지막으로 보조 색인 (Secondary Indexes)은 솔라나 엘라스틱서치 같은 검색 서버에게는 존재의 이유다.

보조 색인 (Secondary Indexes)이 있는 데이터베이스를 파티셔닝하는 데 널리 쓰이는 두 가지 방법이 있다. 문서 기반 파티셔닝과 용어 기반 파티셔닝이다.

### a. 문서 기준 보조 색인 (Secondary Indexes) 파티셔닝

사람들이 차를 검색할 때 **색상과 제조사로 필터링**할 수 있게 하려면 color와 make에 보조 색인 (Secondary Indexes)을 만들어야 한다. 색인(Index)을 선언했다면 데이터베이스가 자동으로 색인(Index) 생성을 할 수 있다.

![](/bin/DDIA_image/Designing_Data_intensive_6_11.png)

이런 색인 방법을 사용하면 각 파티션이 완전히 독립적으로 동작한다. 각 파티션은 자신의 보조 색인 (Secondary Indexes)을 유지하며 **그 파티션에 속하는 문서만 담당**한다. 데이터베이스에 문서 추가, 삭제, 갱신 등의 쓰기 작업을 실행할 때는 쓰려고 하는 문서 ID를 포함하는 파티션만 다루면 된다. 그래서 문서 파티셔닝 색인(Index)은 지역 색인(local index)이라고도 한다.

문서 기준으로 파티셔닝된 색인(Index)을 써서 읽을 때는 주의를 기울여야 한다. 문서 ID에 뭔가 특별한 작업을 하지 않는다면 특정한 색상이거나 특정한 제조사가 만든 자동차가 동일한 파티션에 저장되리라는 보장이 없다. 따라서 빨간색 자동차를 찾고 싶다면 **모든** 파티션으로 질의를 보내서 얻은 결과를 모두 모아야 한다.

파티셔닝된 데이터베이스에 이런 식으로 질의를 보내는 방법을 **스캐터/개더(scatter/gather)** 라고도 하는데 보조 색인 (Secondary Indexes)을 써서 읽는 질의는 큰 비용이 들 수 있다. 여러 파티션에서 질의를 병렬 실행하더라도 스캐터/개더는 꼬리 지연 시간 증폭이 발생하기 쉽다. 그럼에도 보조 색인 (Secondary Indexes)을 문서 기준으로 파티셔닝하는 경우가 많다. 몽고DB, 리악, 카산드라, 엘라스틱서치, 솔라클라우드, 볼트DB는 모두 문서 기준으로 파티셔닝된 보조 색인 (Secondary Indexes)을 사용한다. 데이터베이스 벤더들은 대부분 보조 색인 (Secondary Indexes) 질의가 단일 파티션에서만 실행되도록 파티셔닝 방식을 설계하기를 권장하지만 항상 가능하지는 않다.


### b. 용어 기준 보조 색인 (Secondary Indexes) 파티셔닝

각 파티션이 자신만의 보조 색인 (Secondary Indexes)을 갖게 하는 대신, 모든 파티션의 데이터를 담당하는 **전역 색인 (global index)** 을 만들 수도 있다. 한 노드에만 색인(Index)을 저장할 수는 없다. 해당 노드가 병목이 되어 파티셔닝의 목적을 해치기 때문이다. 전역 색인도 파티셔닝해야 하지만 기본키 색인(Index)과는 다른 식으로 할 수 있다.

![](/bin/DDIA_image/Designing_Data_intensive_6_19.png)

찾고자 하는 용어에 따라 색인의 파티션이 결정되므로 이런 식의 색인(Index)을 **용어 기준으로 파티셔닝됐다(term-partitioned)** 고 한다. **용어**라는 이름은 전문 색인에서 나왔는데 용어란 문서에 등장하는 모든 단어를 말한다.

이전처럼 색인(Index)을 파티셔닝할 때 용어 자체를 쓸 수도 있고 용어의 해시값을 사용할 수도 있다. 용어 자체로 파티셔닝하면 범위 스캔에 유용한 반면 용어의 해시값을 사용해 파티셔닝하면 부하가 좀 더 고르게 분산된다.

문서 파티셔닝 색인에 비해 전역 색인이 갖는 이점은 읽기가 효율적이라는 것이다. 클라이언트는 모든 파티션에 스캐터/개더를 실행할 필요 없이 **원하는 용어를 포함하는 파티션으로만 요청**을 보내면 된다. 그렇지만 전역 색인은 쓰기가 느리고 복잡하다는 단점이 있다. 단일 문서를 쓸 때 해당 색인의 여러 파티션에 영향을 줄 수 있기 때문이다.

이상적인 세상이라면 색인(Index)은 항상 최신 상태에 있고 데이터베이스에 기록된 모든 문서는 바로 색인에 반영돼야 한다. 하지만 용어 파티셔닝 색인을 사용할 때 그렇게 하려면 쓰기에 영향받은 모든 파티션에 걸친 분산 트랜잭션을 실행해야 하는데, 모든 데이터베이스에서 분산 트랜잭션을 지원하지는 않는다. -> 7, 9장

현실에서 전역 보조 색인 (Secondary Indexes)은 대게 비동기로 갱신된다. 아마존 다이나모DB는 정상적인 상황에서는 전역 보조 색인 (Secondary Indexes)을 갱신하는 데 1초도 안걸리지만 인프라에 결함이 생기면 반영 지연 시간이 더 길어질 수도 있다.

전역 용어 파티셔닝 색인의 다른 사용처로는 리악의 검색 기능과 오라클 데이터 웨어하우스가 있다. 오라클 데이터 웨어하우스는 지역 색인과 전역 색인 사이에 선택할 수 있다. -> 12장

## D. 파티션 재균형화 (Rebalancing Partitions)

시간이 지나면 데이터베이스에 변화가 생긴다.

- 질의 처리량이 증가해서 늘어난 부하를 처리하기 위해 CPU를 더 추가하고 싶다.
- 데이터셋 크기가 증가해서 데이터셋 저장에 사용할 디스크와 램을 추가하고 싶다.
- 장비에 장애가 발생해서 그 장비가 담당하던 역할을 다른 장비가 넘겨받아야 한다.

이런 변화가 생기면 데이터와 요청이 한 노드에서 다른 노드로 옮겨져야 한다. 클러스터에서 한 노드가 담당하던 부하를 다른 노드로 옮기는 과정을 **재균형화(rebalancing)** 라고 한다.

어떤 파티셔닝 방식을 쓰는지에 무관하게 재균형화가 실행될 때 보통 만족시킬 것으로 기대되는 최소 요구사항이 있다.

- 재균형화 후, 부하(데이터 저장소, 읽기 쓰기 요청)가 클러스터 내에 있는 노드들 사이에 균등하게 분배돼야 한다.
- 재균형화 도중에도 데이터베이스는 읽기 쓰기 요청을 받아들여야 한다.
- 재균형화가 빨리 실행되고 네트워크와 디스크 I/O 부하를 최소화할 수 있도록 노드들 사이에 데이터가 필요 이상으로 옮겨져셔는 안 된다.

### a. 재균형화 전략 (Strategies for Rebalancing)

#### ㄱ. 쓰면 안 되는 방법: 해시값에 모드 N 연산을 실행

> hash(key) mod 10은 0과 9 사이의 숫자를 반환한다.

모드 N 방식의 문제는 노드 개수 N이 바뀌면 대부분의 키가 노드 사이에 옮겨져야 한다는 점이다.

> hash(key) = 123456
> 처음에 node가 10대라면 이 키는 노드 6에 할당된다. (123456 mod 10 = 6)
> node가 12대로 늘어나면 노드 0으로 옮겨져야 한다. (123456 mod 12 = 0)

이렇게 키가 자주 이동하면 재균형화 비용이 지나치게 커진다.

#### ㄴ. 파티션 개수 고정

파티션을 노드 대수보다 많이 만들고 각 노드에 여러 파티션을 할당하는 것이다.

클러스터에 노드가 추가되면 새 노드는 파티션이 다시 균일하게 분배될 때까지 기존 노드에서 파티션 몇 개를 **뺏어올** 수 있다. 클러스터에서 노드가 제거되면 이 과정이 반대로 실행된다.

![](/bin/DDIA_image/Designing_Data_intensive_6_12.png)

파티션은 노드 사이에서 통째로 이동하기만 한다. 파티션 개수는 바뀌지 않고 파티션에 할당된 키도 변경되지 않는다. 유일한 변화는 **노드에 어떤 파티션이 할당**되는가 뿐이다. 파티션 할당 변경은 즉시 반영되지 않고 네트워크를 통해 대량의 데이터를 전송해야 하므로 시간이 좀 걸린다. 따라서 데이터 전송이 진행 중인 동안에 읽기나 쓰기가 실행되면 기존에 할당된 파티션을 사용한다.

이론상으로 클러스터에 성능이 다른 하드웨어가 섞여 있는 것을 고려할 수도 있다. 성능이 좋은 노드에 파티션을 더 할당함으로써 더 많은 부하를 담당하게 할 수 있다.

이런 재균형화 방법은 리악, 엘라스틱서치, 카우치베이스, 볼드모트에서 사용된다. 이 방식을 사용할 때는 보통 데이터베이스가 **처음 구축될 때 파티션 개수가 고정**되고 이후에 변하지 않는다. 파티션 개수가 고정되면 운영이 단순해지므로 고정 파티션을 사용하는 데이터베이스는 파티션 분할을 지원하지 않는 경우가 많다. 따라서 처음 설정된 파티션 개수가 사용 가능한 노드 대수의 최대치가 되므로 **미래에 증가될 것을 수용하기에 충분히 높은 값으로 선택**해야 한다. 그러나 개별 파티션도 관리 오버헤드가 있으므로 너무 큰 수를 선택하면 역효과를 낳을 수 있다.

각 파티션에는 전체 데이터의 고정된 비율이 포함되므로 개별 파티션 크기는 클러스터의 전체 데이터 크기에 비례해서 증가한다. 파티션이 너무 크면 재균형화를 실행할 때와 노드 장애로부터 복구할 때 비용이 크다. 그러나 파티션이 너무 작으면 오버헤드가 너무 커진다.

#### ㄷ. 동적 파티셔닝

키 범위 파티셔닝을 사용하는 데이터베이스에서는 파티션 경계와 개수가 고정되면, 파티션 경계를 잘못 지정하면 모든 데이터가 한 파티션에 저장되고 나머지 파티션은 텅 빌 수도 있다.

HBase나 리싱크DB처럼 키 범위 파티셔닝을 사용하는 데이터베이스에서는 파티션을 동적으로 만든다. 파티션 크기가 **설정된 값을 넘어서면 파티션을 두 개로 쪼개** 각각에 원래 파티션의 절반 정도의 데이터가 포함되게 한다. 반대로 데이터가 많이 삭제되어 파티션 크기가 임곗값 아래로 떨어지면 인접한 파티션과 합쳐질 수 있다. 이 과정은 B 트리의 최상위 레벨에서 실행되는 작업과 유사하다.

![](/bin/DDIA_image/Designing_Data_intensive_6_13.png)

파티션 개수가 고정된 경우와 마찬가지로 각 파티션은 노드 하나에 할당되고 각 노드는 여러 파티션을 담당할 수 있다. 큰 파티션이 쪼개진 후 부하의 균형을 맞추기 위해 분할된 파티션 중 하나가 다른 노드로 이동될 수 있다. HBase의 경우 기반 분산 파일 시스템인 HDFS를 통해 파티션 파일이 전송된다.

##### 1) 동적 파티셔닝의 장점

동적 파티셔닝은 **파티션 개수가 전체 데이터 용량에 맞춰 조정**된다는 이점이 있다. 데이터 양이 작으면 파티션 개수가 적어도 되므로 오버헤드도 작다. 데이터 양이 거대하다면 개별 파티션의 크기는 설정된 최대치로 제한된다.

##### 2) 동적 파티셔닝의 단점

빈 데이터베이스는 파티션 경계를 어디로 정해야 하는지에 관한 **사전** 정보가 없으므로 시작할 때는 파티션이 하나라는 함정이 있다. 이 문제를 완화하기 위해 HBase와 몽고DB에서는 빈 데이터베이스에 초기 파티션 집합을 설정할 수 있게 한다(**사전 분할(pre-splitting)** 이라고 부른다.) 키 범위 파티셔닝의 경우 사전 분할을 하려면 어떤 식으로 분할될지 미리 알아야 한다.

동적 파티셔닝은 키 범위 파티셔닝에만 적합한 것은 아니고 해시 파티셔닝에도 똑같이 사용될 수 있다.

#### ㄹ. 노드 비례 파티셔닝

**동적 파티셔닝**에서는 개별 파티션 크기가 어떤 고정된 최솟값과 최댓값 사이에 유지되게 하므로 **파티션 개수가 데이터셋 크기에 비례**한다. 반면 **파티션 개수를 고정**하면 **개별 파티션의 크기가 데이터셋 크기에 비례**한다. 두 경우 모두 파티션 개수는 노드 개수와 독립적이다.

카산드라와 케타마(Ketama)에서 사용되는 세 번째 방법은 파티션 개수가 노드 대수에 비례하게 하는 것이다. 다시 말해 **노드당** 할당되는 파티션 개수를 고정한다. 이 경우 노드 대수가 변함 없는 동안은 개별 파티션 크기가 데이터셋 크기에 비례해서 증가하지만 노드 대수를 늘리면 파티션 크기는 다시 작아진다. 일반적으로 데이터 용량이 클수록 데이터를 저장할 노드도 많이 필요하므로 이 방법을 쓰면 개별 파티션 크기도 상당히 안정적으로 유지된다.

![](/bin/DDIA_image/Designing_Data_intensive_6_14.png)

새 노드가 클러스터에 추가되면 고정된 개수의 파티션을 무작위로 선택해 분할하고 각 분할된 파티션의 절반은 그대로 두고 다른 절반은 새 노드에 할당한다. 파티션을 무작위로 선택해서 균등하지 않은 분할이 생길 수 있지만 여러 파티션에 대해 **평균적**으로 보면 새 노드는 기존 노드들이 담당하던 부하에서 **균등한 몫을 할당**받게 된다. 카산드라 3.0에는 불균등한 분할을 회피할 수 있는 대안적인 재균형화 알고리즘이 추가됐다.

 파티션 경계를 무작위로 선택하려면 해시 기반 파티셔닝을 사용해야 한다. 실제로 이 방법은 일관성 해싱의 원래 정의에 가장 가깝게 대응한다. 최근에 나온 해시 함수를 쓰면 메타데이터 오버헤드를 낮추면서도 비슷한 효과를 얻을 수 있다.
 
 ### b. 운영: 자동 재균형화와 수동 재균형화 (Operations: Automatic or Manual Rebalancing)
 
 재균형화에 관한 중요한 의문이 하나 있다. 재균형화는 자동으로 실행될까? 아니면 수동으로 실행해야 할까?
 
 완전 자동 재균형화와 완전 수동 재균형화 사이에는 **중간 지점**이 있다. 이를테면 카우치베이스, 리악, 볼드모트는 **자동으로 파티션 할당을 제안**하지만 **반영되려면 관리자가 확정**해야 한다.
 
 완전 자동 재균형화는 일상적인 유지보수에 손이 덜 가므로 편리할 수 있다. 하지만 예측하기 어렵기도 하다. 재균형화는 요청 경로를 재설정해야 하고 대량의 데이터를 노드 사이에 이동해야 하므로 비용이 큰 연산이다. 주의 깊게 처리하지 않으면 네트워크나 노드에 과부하가 걸릴 수 있고 재균형화가 진행 중인 동안에 실행되는 다른 요청의 성능이 저하될 수 있다.
 
 이런 이유로 재균형화 과정에 사람이 개입하는 게 좋을 수도 있다. 완전 자동 처리보다는 느릴 수 있지만 운영상 예상치 못한 일을 방지하는 데 도움될 수 있다.
 
 ![](/bin/DDIA_image/Designing_Data_intensive_6_15.png)
 
 ## E. 요청 라우팅 (Request Routing)
 
 클라이언트에서 요청을 보내려고 할 때 **어느 노드로 접속해야 하는지** 어떻게 알 수 있을까? 파티션이 재균형화되면서 노드에 할당되는 파티션이 바뀐다. 
 
 파티션 할당 변경을 훤히 알고 있어야 하는 문제는 데이터베이스에 국한되지 않은 더욱 일반적인 문제인 서비스 찾기(service discovery)의 일종이다. 네트워크를 통해 접속되는 소프트웨어라면 어떤 것이든지, 특히 고가용성을 지향하는 소프트웨어라면 모두 이 문제가 있다.
 
 상위 수준에서 보면 이 문제는 몇 가지 다른 접근법이 있다.
 
![](/bin/DDIA_image/Designing_Data_intensive_6_16.png)

 1. 클라이언트가 아무 노드에나 접속하게 한다. 만약 해당 **노드**에 마침 요청을 적용할 파티션이 있다면 거기서 요청을 직접 처리할 수 있다. 그렇지 않으면 요청을 올바른 노드로 전달해서 응답을 받고 클라이언트에게 응답을 전달한다.
 2. 클라이언트의 모든 요청을 **라우팅 계층**으로 먼저 보낸다. 라우팅 계층에서는 각 요청을 처리할 노드를 알아내고 그에 따라 해당 노드로 요청을 전달한다. 라우팅 계층 자체에서는 아무 요청도 처리하지 않는다. 파티션 인지(partition-aware) 로드밸런서로 동작할 뿐이다.
	 - 소프트웨어 디자인 패턴에서 mediator pattern
1. **클라이언트**가 파티셔닝 방법과 파티션이 어떤 노드에 할당됐는지를 알고 있게 한다. 이 경우 클라이언트는 중개자 없이 올바른 노드로 직접 접속할 수 있다.

모든 경우에 핵심 문제는 라우팅 결정을 내리는 구성요소가 **노드에 할당된 파티션의 변경 사항을 어떻게 아느냐**다.

![](/bin/DDIA_image/Designing_Data_intensive_6_17.png)

많은 분산 데이터 시스템은 클러스터 메타데이터를 추적하기 위해 주키퍼(ZooKeeper) 같은 별도의 코디네이션 서비스를 사용한다. 각 노드는 주키퍼에 자신을 등록하고 주키퍼는 파티션과 노드 사이의 신뢰성 있는 할당 정보를 관리한다. 라우팅 계층이나 파티션 인지 클라이언트 같은 다른 구성요소들은 주키퍼에 있는 정보들 구독할 수 있다. 파티션 소유자가 바뀌든지, 노드가 추가되거나 삭제되면 주키퍼는 라우팅 계층에 이를 알려서 라우팅 정보를 최신으로 유지할 수 있게 한다.

링크드인의 에스프레소는 헬릭스(Helix)를 써서 클러스터를 관리하며 위 그림의 라우팅 계층을 구현한다. HBase, 솔라클라우드, 카프카도 파티션 할당을 추적하는 데 주키퍼를 사용한다. 몽고DB도 아키텍처는 비슷하지만 자체적인 **설정 서버(config server)** 구현에 의존하고 **몽고스(mongos)** 데몬을 라우팅 계층으로 사용한다.

카산드라와 리악은 다른 방법을 쓴다. **가십 프로토콜(gossip protocol)** 을 사용해서 클러스터 상태 변화를 노드 사이에 퍼뜨린다. 아무 노드나 요청을 받을 수 있고 요청을 받은 노드는 요청을 처리할 파티션을 갖고 있는 올바른 노드로 요청을 전달해준다. 이 모델은 데이터베이스 노드에 복잡성을 더하지만 주키퍼 같은 외부 코디네이션 서비스에 의존하지 않는다.

카우치베이스는 재균형화를 자동으로 실행하지 않아서 설계가 단순하다.  보통 클러스터 노드로부터 변경된 라우팅 정보를 알아내는 목시(moxi)라는 라우팅 계층을 설정한다.

클라이언트는 라우팅 계층을 사용하거나 임의의 노드로 요청을 보낼 때도 접속할 IP 주소를 알아내야 한다. IP 주소는 노드에 할당된 파티션 정보만큼 자주 바뀌지 않으므로 IP 주소를 찾는 데는 대게 DNS를 쓰는 것으로 충분하다.

### a. 병렬 질의 실행 (Parallel Query Execution)

지금까지는 단일 키를 읽거나 쓰는 매우 간단한 질의에 대해서만 설명했다. 이는 대부분의 NoSQL 분산 데이터스토어에서 지원되는 접근 수준이다.

그러나 분석용으로 자주 사용되는 **대규모 병렬 처리(massively parallel processing, MPP)** 관계형 데이터베이스 제품은 훨씬 더 복잡한 종류의 질의를 지원한다. 전형적인 데이터 웨어하우스 질의는 조인(join), 필터링(filtering), 그룹화(grouping), 집계(aggregation) 연산을 몇 개 포함한다. MPP 질의 최적화기는 복잡한 질의를 **여러 실행 단계와 파티션으로 분해**하며 이들 중 다수는 데이터베이스 클러스터 내의 서로 다른 노드에서 병렬적으로 실행될 수 있다. 데이터셋의 많은 부분을 스캔하는 연산을 포함하는 질의는 특히 병렬 실행의 혜택을 받는다.

데이터 웨어하우스 질의 고속 병렬 실행은 전문적인 주제이며 분석 업무가 비즈니스적으로 중요해짐에 따라 상업적 관심을 많이 받고 있다.

```

MPP (Massive Parallel Processing)

- 멀티코어를 활용하면서 디스크 I/O를 병렬 처리하는 아키텍쳐
- 여러 디스크에 분산된 데이터가 서로 다른 CPU 코어에 의해 읽혀 부분적인 실행이 이루어진다. 그 결과들은 한 곳에 모이고 최종적인 결과가 출력된다.
- 위의 일련의 처리는 가능한 동시에 병렬로 실행된다.
- Amazon Redshift, Google BigQuery

```

![](/bin/DDIA_image/Designing_Data_intensive_6_18.png)

## F. 정리

대용량 데이터셋을 더욱 작은 데이터셋으로 파티셔닝하는 다양한 방법을 살펴봤다. 저장하고 처리할 데이터가 너무 많아서 장비 한 대로 처리하는 게 불가능해지면 파티셔닝이 필요하다.

파티셔닝의 목적은 핫스팟이 생기지 않게 하면서 데이터와 질의 부하(query load)를 여러 장비에 균일하게 분배하는 것이다. 그렇게 하려면 데이터에 적합한 파티셔닝 방식을 선택해야 하고 클러스터에 노드가 추가되거나 제거될 때 파티션 재균형화를 실행해야 한다.

### a. 주요 파티셔닝 기법

아래 두 가지 방법을 섞어 쓸 수도 있다.
- 키의 일부분은 파티션 식별용으로, 나머지 부분은 정렬 순서용으로 만든 복합키를 사용하는 것이다.

#### ㄱ. 키 범위 파티셔닝

- 키가 정렬돼 있고 개별 파티션은 어떤 최솟값과 최댓값 사이에 속하는 모든 키를 담당한다.
- 범위 질의가 효율적이라는 장점.
- 애플리케이션에서 정렬 순서가 서로 가까운 키에 자주 접근하면 핫스팟이 생길 위험이 있다.
- 보통 한 파티션이 너무 커지면 키 범위를 두 개로 쪼개 동적으로 재균형화를 실행한다.

#### ㄴ. 해시 파티셔닝

- 각 키에 해시 함수를 적용하고 개별 파티션은 특정 범위의 해시값을 담당한다.
- 키 순서가 보정되지 않아 범위 질의가 비효율적이다.
- 부하를 더욱 균일하게 분산할 수 있다.
- 보통 고정된 개수의 파티션을 미리 만들어 각 노드에 몇 개씩의 파티션을 할당하여 노드가 추가되거나 제거되면 파티션을 통째로 노드 사이에서 이동한다.
- 동적 파티셔닝을 쓸 수도 있다.

### b. 보조 색인의 파티셔닝

#### ㄱ. 문서 파티셔닝 색인(지역 색인)

- 보조 색인을 기본키와 값이 저장된 파티션에 저장한다.
- 쓸 때는 파티션 하나만 갱신하면 되지만 보조 색인을 읽으려면 모든 파티션에 걸쳐서 스캐터/개더를 실행해야 한다.

#### ㄴ. 용어 파티셔닝 색인(전역 색인)

- 색인된 값을 사용해서 보조 색인을 별도로 파티셔닝한다.
- 보조 색인 항목은 기본키의 모든 파티션에 있는 레코드를 포함할 수도 있다.
- 문서를 쓸 때는 보조 색인 여러 개를 갱신해야 하지만 읽기는 단일 파티션에서 실행될 수 있다.

---

설계상 모든 파티션은 대부분 독립적으로 동작한다. 그렇기 때문에 파티셔닝된 데이터베이스는 여러 장비로 확장될 수 있다. 그러나 여러 파티션에 기록해야 하는 연산은 따져 보기 어려울 수 있다.

# 참고문헌

[1] 마틴 클레프만, 정재부 등 3인 옮김, "데이터 중심 애플리케이션 설계", 3쇄, 위키북스, 2021년
