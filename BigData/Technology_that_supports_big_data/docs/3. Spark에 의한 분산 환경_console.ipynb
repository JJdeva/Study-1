{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5299a597",
   "metadata": {},
   "source": [
    "# Spark에 의한 분산 환경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed76be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyspark --packages org.mongodb.spark:mongo-spark-connector_2.11:2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7926adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark세션 정보에 접근하기 위한 변수\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db70e72",
   "metadata": {},
   "source": [
    "### A. MongoDB의 애드 혹 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c74df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB로 부터 데이터가져와서 데이터프레임 형태로 변경\n",
    "df = (spark.read\n",
    "    .format(\"com.mongodb.spark.sql.DefaultSource\")\n",
    "    .option(\"uri\", \"mongodb://localhost/twitter.sample\")\n",
    "    .load())\n",
    "\n",
    "# 데이터프레임을 일시적인 뷰로 등록\n",
    "df.createOrReplaceTempView('tweets')\n",
    "\n",
    "# 언어별 트윗 수의 상위 3건 표시하는 쿼리 작성\n",
    "query = '''\n",
    "SELECT lang, count(*) count\n",
    "FROM tweets \n",
    "WHERE delete IS NULL \n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "'''\n",
    "\n",
    "# 쿼리 실행\n",
    "spark.sql(query).show(3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a95f36b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "+----+------+\n",
    "|lang| count|\n",
    "+----+------+\n",
    "|  en|684768|\n",
    "|  ja|383212|\n",
    "| und|185301|\n",
    "+----+------+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a081619",
   "metadata": {},
   "source": [
    "### B. 텍스트 데이터의 가공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b4aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 트윗과 글작성 시간 추출\n",
    "en_query = '''\n",
    "SELECT from_unixtime(timestamp_ms / 1000) time,\n",
    "       text\n",
    "FROM tweets\n",
    "WHERE lang='en'\n",
    "'''\n",
    "\n",
    "# en_query를 실행해서 데이터프레임을 만든다.\n",
    "en_tweets=spark.sql(en_query)\n",
    "\n",
    "from pyspark.sql import Row\n",
    "\n",
    "# 트윗을 단어로 분해하는 제네레이터 함수\n",
    "def text_split(row):\n",
    "    for word in row.text.split():\n",
    "        yield Row(time=row.time, word=word)\n",
    "        \n",
    "# '.rdd'로 원시 레코드 참조\n",
    "en_tweets.rdd.take(1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62926a9d",
   "metadata": {},
   "source": [
    "[Row(time='2022-02-01 20:13:50', text='RT @Preeti_Nishad5: My idol has a wax statue at Madame Tussauds and his idol was invited for 2021 actors roundtable the difference 🤧🤧')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762424ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatMap()에 제네레이터 함수 적용\n",
    "en_tweets.rdd.flatMap(text_split).take(2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e0df4c7",
   "metadata": {},
   "source": [
    "[Row(time='2022-02-01 20:13:50', word='RT'), Row(time='2022-02-01 20:13:50', word='@Preeti_Nishad5:')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# toDF()를 사용해 데이터 프레임으로 변환\n",
    "en_tweets.rdd.flatMap(text_split).toDF().show(2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b846908a",
   "metadata": {
    "title": "-------------------+------------+"
   },
   "source": [
    "+-------------------+----------------+\n",
    "|               time|            word|\n",
    "+-------------------+----------------+\n",
    "|2022-02-01 20:13:50|              RT|\n",
    "|2022-02-01 20:13:50|@Preeti_Nishad5:|\n",
    "+-------------------+----------------+\n",
    "only showing top 2 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521014aa",
   "metadata": {},
   "source": [
    "### C. Spark 프로그램에 있어서의 DAG 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a8dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 분해한 단어로 이루어진 뷰 'words'를 작성\n",
    "words = en_tweets.rdd.flatMap(text_split).toDF()\n",
    "words.createOrReplaceTempView('words')\n",
    "\n",
    "# 단어별 카운트의 상위 3건을 표시\n",
    "word_count_query = '''\n",
    "SELECT word, count(*) count\n",
    "FROM words\n",
    "GROUP BY 1\n",
    "ORDER BY 2 DESC\n",
    "'''\n",
    "\n",
    "spark.sql(word_count_query).show(3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "799c42d4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "+----+------+\n",
    "|word| count|\n",
    "+----+------+\n",
    "|  RT|403096|\n",
    "| the|203869|\n",
    "|  to|161376|\n",
    "+----+------+\n",
    "only showing top 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8ba6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# 분해한 단어를 테이블로 보관\n",
    "words.write.saveAsTable('twitter_sample_words')\n",
    "\n",
    "# 초기 설정에서는 'spark-warehouse'에 파일이 저장된다.\n",
    "# ./spark-warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57be8e61",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "big_data",
   "language": "python",
   "name": "big_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}