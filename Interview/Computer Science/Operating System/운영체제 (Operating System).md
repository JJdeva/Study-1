# 1. 프로세스와 스레드의 차이

- 프로세스는 운영체제로부터 자원을 할당받아 실행하고, 스레드는 프로세스로부터 자원을 할당받아 실행한다.

- 하나의 프로세스 안에서 여러 스레드 생성이 가능하며, 각 스레드는 개별 스택을 가지고, 프로세스의 전역 메모리 공간을 공유하며 프로그램을 실행한다.
	- 보통 프로세스는 코드/데이터/스택/힙 메모리 영역을 기반으로 실행하며, 스레드는 프로세스 안에서 개별적인 스택을 가지고 코드/데이터/힙 영역을 공유하며 실행한다.

- 코드
	- 코드를 저장
- 데이터
	- 전역 변수, 정적 변수, 배열
- 힙
	- 동적 메모리 할당
- 스택
	- 지역 변수, 매개 변수, 리턴 값

## A. 스레드

프로세스에서 제어만 분리한 실행 단위

## B. 프로세스의 상태 변화

준비 -> 실행 = 디스패치(dispatch)
실행 -> 준비 = timeout
준비 -> 대기 = block
대기 -> 준비 = wakeup

## C. 프로세스 주소 공간

프로세스 주소 공간에는 코드, 데이터, 스택으로 이루어져 있다.

- 코드 Segment
	- 프로그램 소스 코드 저장
- 데이터 Segment
	- 전역 변수 저장
- 스택 Segment
	- 함수, 지역 변수 저장

### a) 왜 이렇게 구역을 나눈건가?

최대한 데이터를 공유하여 메모리 사용량을 줄여야 한다.

Code는 같은 프로그램 자체에서는 모두 같은 내용이기 때문에 따로 관리하여 공유한다.

Stack과 data를 나눈 이유는, 스택 구조의 특성과 전역 변수의 활용성을 위한 것이다.

![](https://t1.daumcdn.net/cfile/tistory/2174013858F1BED70A)

프로그램의 함수와 지역 변수는, LIFO(가장 나중에 들어간게 먼저 나옴)특성을 가진 스택에서 실행된다. 따라서 이 함수들 안에서 공통으로 사용하는 **전역 함수**는 따로 지정해주면 메모리를 아낄 수 있다.

# 2. 오버헤드

어떤 처리를 하기 위해 소요되는 간접적인 처리 시간, 메모리 등을 말한다.

# 3. 동기와 비동기

## A. 동기

어떤 일에 대한 요청을 보내고 응답이 올때까지 기다리고 다음 요청을 수행한다.

### a. 장점

구현이 쉽다.

### b. 단점

요청을 보내고 응답이 올때까지 자원을 점유하고 있어야 하므로 자원의 낭비가 발생한다.

## B. 비동기

어떤 일에 대한 요청을 보내고, 응답을 기다리지 않고 다음 요청을 보낸다.

### a. 장점

동시에 여러 일을 처리할 수 있다.

### b. 단점

요청이 많아져 시스템에 부하가 발생할 수 있다.

# 4. deadlock의 개념 및 deadlock 해결 방법

## A. deadlock

운영체제에서 데드락(교착상태)이란, 시스템 자원에 대한 요구가 뒤엉킨 상태이다.

둘 이상의 프로세스가 다른 프로세스가 점유하고 있는 자원을 서로 기다릴 때 무한 대기에 빠지는 상황을 말한다.

멀티 프로그래밍 환경에서 한정된 자원을 얻기 위해 서로 경쟁하는 상황 발생

한 프로세스가 자원을 요청했을 때, 동시에 그 자원을 사용할 수 없는 상황이 발생할 수 있음. 이때 프로세스는 대기 상테로 들어감. 대기 상태로 들어간 프로세스들이 실행 상태로 변경될 수 없을 때 **교착 상태** 발생

## B. deadlock 발생 조건

- 상호배제
	- 한 번에 프로세스 하나만 해당 자원을 사용할 수 있다.
	- 사용 중인 자원을 다른 프로세스가 사용하려면 요청한 자원이 해제될 때까지 기다려야 한다.
- 점유와 대기
	- 자원을 최소한 하나 보유하고, 다른 프로세스에 할당된 자원을 점유하기 위해 대기하는 프로세스가 존재해야 한다.
- 비선점
	- 프로세스에 이미 할당된 자원을 강제로 빼앗을 수 없다.
- 순환 대기
	- 대기 프로세스의 집합이 순환 형태로 자원을 대기하고 있어야 한다.

## C. deadlock 해결 방법

- 데드락이 발생하지 않도록 예방(prevention)하기
- 데드락 발생 가능성을 인정하면서도 적절하게 회피(avoidance)하기
- 데드락 발생을 허용하지만 데드락을 탐지(detection)하여, 데드락에서 회복하기

### a. 데드락 예방

데드락 발생 조건 4가지 중 하나라도 발생하지 않도록 하는 것.

- 자원의 상호배제 조건 방지
	- 한 번에 여러 프로세스가 공유 자원을 사용할 수 있게 한다.
- 점유와 대기 조건 방지
	- 프로세스 실행에 필요한 모든 자원을 한꺼번에 요구하고 허용할 때까지 작업을 보류해서, 나중에 또 다른 자원을 점유하기 위한 대기 조건을 성립하지 않도록 한다.
- 비선점 조건 방지
	- 이미 다른 프로세스에게 할당된 자원이 선점권이 없다고 가정할 때, 높은 우선순위의 프로세스가 해당 자원을 선점할 수 있도록 한다.
- 순환 대기 조건 방지
	- 자원을 순환 형태로 대기하지 않도록 일정한 한 쪽 방향으로만 자원을 요구할 수 있도록 한다.

#### 1) 단점

시스템의 처리량이나 효율성을 떨어트리는 단점이 발생할 수 있다.

### b. 데드락 회피

- 안정 상태 (safe state)
	- 시스템의 프로세스들이 요청하는 모든 자원을, 데드락을 발생시키지 않으면서도 차례로 모두에게 할당해 줄 수 있다면 안정 상태에 있다고 말한다.
- 안전 순서 (safe sequence)
	- 특정한 순서로 프로세스들에게 자원을 할당, 실행 및 종료 등의 작업을 할 때 데드락이 발생하지 않는 순서를 찾을 수 있다면, 그것을 안전 순서라고 부른다.
- 불안정 상태
	- 안정 상태가 아닌 상황
	- 데드락 발생 가능성이 있는 상황
	- 교착 상태(데드락)는 불안정 상태일 때 발생할 수 있다.
		- 교착 상태(데드락)는 불안정 상태일 때 발생할 수 있다.
		- 불안정 상태가 좀 더 큰 집합이다.

회피 알고리즘은 자원을 할당한 후에도 시스템이 항상 safe state에 있을 수 있도록 할당을 허용하자는 것이 기본 특징이다.

#### 1) 은행원 알고리즘 (Banker's Algorithm)

다익스트라가 제안한 방법

미리 결정된 모든 자원들의 최대 가능한 할당량을 가지고 시뮬레이션해서 Safe state에 들 수 있는지 여부를 검사한다. 즉, 대기중인 다른 프로세스들의 활동에 대한 교착 상태 가능성을 미리 조사하는 것이다.

[[운영체제] 데드락(Deadlock, 교착 상태)이란? | ChanBLOG (chanhuiseok.github.io)](https://chanhuiseok.github.io/posts/cs-2/)

은행원 알고리즘은 미리 최대 자원 요구량을 알아야 하고, 할당할 수 있는 자원 수가 일정해야 하는 등 사용에 있어 제약조건이 많고, 그에 따른 자원 이용도 하락 등 단점도 존재한다.

### c. 데드락 탐지 및 회복

데드락 예방이나 회피법을 사용하지 않았을 때, 데드락이 발생할 수 있으니 여기에서 회복하기 위해 데드락을 탐지하고 회복하는 알고리즘을 사용한다.

#### 1) 탐지 기법

은행원 알고리즘에서 했던 방식과 유사하게 현재 시스템의 자원 할당 상태를 가지고 데드락이 발생했는지 여부를 탐색한다. (Allocation, Request, Available 등)

자원 할당 그래프를 통해 탐지하는 방법도 있다.

#### 2) 회복 기법

데드락을 탐지 기법을 통해 발견했다면, 순환 대기에서 벗어나 데드락으로부터 회복하기 위한 방법을 사용한다.

- 단순히 프로세스를 1개 이상 중단시키기
	- 교착 상태에 빠진 모든 프로세스를 중단시키는 방법
		- 계속 연산중이던 프로세스들도 모두 일시에 중단되어 부분 결과가 폐기될 수 있는 부작용이 발생할 수 있음.
	- 프로세스를 하나씩 중단시킬 때마다 탐지 알고리즘으로 데드락을 탐지하면서 회복시키는 방법
		- 매번 탐지 알고리즘을 호출 및 수행해야 하므로 부담이 되는 작업일 수 있음
- 자원 선점하기
	- 프로세스에 할당된 자원을 선점해서, 교착 상태를 해결할 때까지 그 자원을 다른 프로세스에 할당해 주는 방법

## D. Starvation (기아 상태)

특정 프로세스의 우선순위가 낮아서 원하는 자원을 계속 할당 받지 못하는 상태를 말한다.

### a. 기아 상태 해결 방안

- 프로세스 우선순위 수시 변경을 통해 각 프로세스 높은 우선순위를 가지도록 기회 부여
- 오래 기다린 프로세스의 우선순위 높이기
- 우선순위가 아닌 요청 순서대로 처리하는 요청 큐 사용

## E. Deadlock vs Starvation

- 교착 상태
	- 여러 프로세스가 동일한 자원 점유를 요청할 때 발생
- 기아 상태
	- 여러 프로세스가 부족한 자원을 점유하기 위해 경쟁할 때 발생

# 5. 뮤텍스와 세마포어

## A. 뮤텍스

한 쓰레드, 프로세스에 의해 소유될 수 있는 **Key**를 기반으로 한 상호배제기법

동기화 대상이 하나.

## B. 세마포어

현재 공유자원에 접근할 수 있는 쓰레드, 프로세스의 수를 나타내는 값을 두어 상호배제를 달성하는 기법

동기화 대상이 하나 이상.

[뮤텍스(Mutex)와 세마포어(Semaphore)의 차이 (tistory.com)](https://worthpreading.tistory.com/90)
 
 ### a. 세마포어 P, V 연산
 
 - P
	 - 임계 영역에 들어가기 전에 수행 (프로세스 진입 여부를 자원의 개수(S)를 통해 결정)
 - V
	 - 임계 영역에서 나올 때 수행 (자원 반납 알림, 대기 중인 프로세스를 깨우는 신호)
 
 #### 1) 구현 방법

```
P(S);

// --- 임계 구역 ---

V(S);
```

```
procedure P(S)   --> 최초 S값은 1임
    while S=0 do wait  --> S가 0면 1이 될때까지 기다려야 함
    S := S-1   --> S를 0로 만들어 다른 프로세스가 들어 오지 못하도록 함
end P

--- 임계 구역 ---

procedure V(S) --> 현재상태는 S가 0임
    S := S+1   --> S를 1로 원위치시켜 해제하는 과정
end V
```
 
 이를 통해, 한 프로세스가 P 혹은 V를 수행하고 있는 동안 프로세스가 인터럽트 당하지 않게 된다. P와 V를 사용하여 임계 영역에 대한 상호배제 구현이 가능하게 되었다.
 
 #### 2) 예시
 
 > 최초 S 값은 1이고, 현재 해당 구역을 수행할 프로세스 A, B가 있다고 가정하자

1. 먼저 도착한 A가 P(S)를 실행하여 S를 0으로 만들고 임계 영역에 들어감
2. 그 뒤 도착한 B가 P(S)를 실행하지만 S가 0이므로 대기 상태
3. A가 임계영역 수행을 마치고 V(S)를 실행하면 S는 다시 1이 됨
4. B는 이제 P(S)에서 while문을 빠져나올 수 있고, 임계영역으로 들어가 수행함


 
# 6. 가상 메모리

## A. 가상 메모리

- 메모리가 실제 메모리보다 많아 보이게 하는 기술
- 가상 메모리는 메모리를 관리하는 또 다른 형태로, 각 프로그램에 실제 메모리 주소가 아닌 가상 메모리 주소를 주는 방법
- 프로그램 전체를 동시에 실행하지 않으므로 요구한 메모리 전체가 아닌 일부만 적재해도 실행이 가능하다.
- 메모리에 로드된, 실행중인 프로세스가 메모리가 아닌 가상의 공간을 참조해 마치 커다란 물리 메모리를 갖는 것처럼 사용할 수 있게 해주는 기법

### a. 가상 메모리 기본 아이디어

- 프로세스는 가상 주소를 사용하고, 실제 해당 주소에서 데이터를 읽고/쓸때만 물리 주소로 바꿔주면 된다.
- virtual address (가상 주소)
	- 프로세스가 참조하는 주소
- physical address (물리 주소)
	- 실제 메모리 주소

## A. 가상 메모리가 필요한 이유

- 메모리 용량 부족 이슈
- 프로세스 메모리 영역간 침범 이슈

# 7. 컨텍스트 스위칭

멀티프로세스 환경에서 CPU가 어떤 하나의 프로세스를 실행하고 있는 상태에서 인터럽트 요청에 의해 다음 우선 순위인 프로세스가 실행되어야 할 때 기존의 프로세스의 상태 또는 레지스터 값을 저장하고 CPU가 다음 프로세스를 수행하도록 새로운 프로세스의 상태 또는 레지스터 값을 교체하는 작업

## A. Context

사용자와 다른 사용자, 사용자와 시스템 또는 디바이스간의 상호작용에 영향을 미치는 사람, 장소, 개체 등의 현재 상황(상태)을 규정하는 정보들을 말한다.

CPU가 해당 프로세스를 실행하기 위한 해당 프로세스의 정보들을 Context라고 한다.

Context는 프로세스의 PCB (Process Control Block)에 저장된다.

그래서 Context Switching 때 PCB의 정보를 읽어(적재) CPU가 전에 프로세스가 일을 하던거에 이어서 수행이 가능한 것이다.

Context Switching 때 해당 CPU는 아무런 일을 하지 못한다. 따라서 컨텍스트 스위칭이 잦아지면 오히려 오버헤드가 발생해 효율(성능)이 떨어진다.

## B. Context Switching (인터럽트, Interrupt)

인터럽트는 CPU가 프로그램을 실행하고 있을 때 실행중인 프로그램 밖에서 예외 상황이 발생하여 처리가 필요한 경우 CPU에게 알려 예외 상황을 처리할 수 있도록 하는 것을 말한다.

지금 수행 중인 일보다 더 중요한 일(입출력, 우선 순위 연산 등)이 발생하면 그 일을 먼저 처리하고 나서 하던 일을 계속해야한다.

외부/내부 인터럽트는 `CPU의 하드웨어 신호에 의해 발생`

소프트웨어 인터럽트는 `명령어의 수행에 의해 발생`

### a. 어떤 인터럽트 요청이 와야 Context Switching이 일어날까?

1. I/O request (입출력 요청할 때)
2. time slice expired (CPU 사용시간이 만료되었을 때)
3. fork a child (자식 프로세스를 만들 때)
4. wait for an interrupt (인터럽트 처리를 기다릴 때)

### b. 인터럽트 종류

#### 1) 외부 인터럽트

입출력 장치, 타이밍 장치, 전원 등 외부적인 요인으로 발생

`전원 이상, 기계 착오, 외부 신호, 입출력`

#### 2) 내부 인터럽트

Trap이라고 부르며, 잘못된 명령이나 데이터를 사용할 때 발생

> 0으로 나누기가 발생, 오버플로우, 명령어를 잘못 사용한 경우 (Exception)

#### 3) 소프트웨어 인터럽트

프로그램 처리 중 명령의 요청에 의해 발생한 것 (SVC 인터럽트)

> 사용자가 프로그램을 실행시킬 때 발생
> 소프트웨어 이용 중에 다른 프로세스를 실행시키면 시분할 처리를 위해 자원 할당 동작이 수행된다.

### c. 인터럽트 발생 처리 과정

![](https://mblogthumb-phinf.pstatic.net/20160310_124/scw0531_14575366291105WjS7_PNG/ERTRTETRE.png?type=w2)

주 프로그램이 실행되다가 인터럽트가 발생했다.

현재 수행 중인 프로그램을 멈추고, 상태 레지스터와 PC 등을 스택에 잠시 저장한 뒤에 인터럽트 서비스 루틴으로 간다. (인터럽트 서비스 루틴이 끝난 뒤 다시 원래 작업으로 돌아와야 하기 때문에 잠시 저장한다)

만약 인터럽트 기능이 없었다면, 컨트롤러는 특정한 어떤 일을 할 시기를 알기 위해 계속 체크를 해야 한다. (이를 폴링(Polling)이라고 한다.)

폴링을 하는 시간에는 원래 하던 일에 집중할 수가 없게 되어 많은 기능을 제대로 수행하지 못하는 단점이 있었다.

#### 1) 컨트롤러가 입력을 받아들이는 방법 (우선순위 판별방법)

##### ㄱ) 폴링 방식

사용자가 명령어를 사용해 입력 핀의 값을 계속 읽어 변화를 알아내는 방식

인터럽트 요청 플래그를 차례로 비교하여 우선순위가 가장 높은 인터럽트 자원을 찾아 이에 맞는 인터럽트 서비스 루틴을 수행한다. (하드웨어에 비해 속도 느림)

##### ㄴ) 인터럽트 방식

MCU 자체가 하드웨어적으로 변화를 체크하여 변화 시에만 일정한 동작을 하는 방식

- Daisy Chain
- 병렬 우선순위 부여

인터럽트 방식은 하드웨어로 지원을 받아야 하는 제약이 있지만, 폴링에 비해 신속하게 대응하는 것이 가능하다. 따라서 실시간 대응이 필요할 때는 필수적인 기능이다.

즉, 인터럽트는 발생시기를 예측하기 힘든 경우에 컨트롤러가 가장 빠르게 대응할 수 있는 방법이다.

# 8. 임계영역 (Critical Section)

임계 영역에는 다수의 프로세스가 접근할 수 있지만, 어느 한 순간에는 프로세스 하나만 사용할 수 있다.

여러 프로세스가 데이터를 공유하며 수행될 때, 각 프로세스에서 공유 데이터를 접근하는 프로그램 코드 부분

공유 데이터를 여러 프로세스가 동시에 접근할 때 잘못된 결과를 만들 수 있기 때문에, 한 프로세스가 임계 영역을 수행할 때는 다른 프로세스가 접근하지 못하도록 해야 한다.

## A. 임계영역의 3가지 조건

1. 상호배제
	- 한번에 하나의 프로세스만 해당 자원을 사용한다.
2. 진행
	- 어떤 프로세스가 들어갈지 적절히 결정해야 한다.
3. 한정 대기
	- 무한정 기다리는 상황을 방지

# 9. 멀티 프로세스, 멀티 스레드

## A. 멀티 프로세스

두개 이상 다수의 프로세서(CPU)가 협력적으로 하나 이상의 작업(Task)을 동시에 처리하는 것이다. (병렬처리)

각 프로세스 간 메모리 구분이 필요하거나 독립된 주소 공간을 가져야 할 경우 사용한다.

### a. 장점

여러 개의 자식 프로세스 중 하나에 문제가 발생하면 그 자식 프로세스만 죽고 다른 프로세스에는 영향이 확산되지 않는다.

### b. 단점

- 프로세스를 변경할 때 Context Switching 과정에서 오버헤드가 발생할 수 있다.
- 프로세스 사이의 어렵고 복잡한 통신 기법 (IPC)

## B. 멀티 스레드

하나의 프로세스에서 여러 스레드로 자원을 공유하며 작업을 나누어 수행한다.

### a. 장점

- 시스템 자원 소모 감소 (자원의 효율성 증대)
- 시스템 처리량 증가 (처리 비용 감소)
- 간단한 통신 방법으로 인한 프로그램 응답 시간 단축

### b. 단점

- 주의 깊은 설계가 필요하다.
- 디버깅이 까다롭다.
- 단일 프로세스 시스템일 경우 효과를 기대하기 어렵다.
	- 프로세스가 여러 개일 때는, 프로그램을 멀티 프로세스로 처리하는 것보다 멀티 스레드로 처리하는 것이 효율적
- 다른 프로세스에서 스레드를 제어할 수 없다. (프로세스 밖에서 스레드 각각을 제어할 수 없다.)
- 자원 공유의 문제가 발생한다. (동기화 문제)
- 하나의 스레드에 문제가 발생하면 전체 프로세스가 영향을 받는다.

#### 1) 극복

멀티 스레드의 안전성에 대한 단점은 임계영역의 조건인 상호배제, 진행, 한정 대기를 통해 대비할 수 있다.

# 10. 운영체제

운영체제는 시스템의 자원과 동작을 관리하는 소프트웨어이다.

# 11. System Call

fork(), exec(), wait()와 같은 것들은 Process 생성과 제어를 위한 System Call

- fork, exec는 새로운 Process 생성과 관련이 되어 있다.
- wait는 Process(Parent)가 만든 다른 Process(Child)가 끝날 때까지 기다리는 명령어다,

## A. Fork

- 새로운 Process를 생성할 때 사용, 그러나 이상한 방식임.

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

int main(int argc, char *argv[]) {
    printf("pid : %d", (int) getpid()); // pid : 29146
    
    int rc = fork();					// 주목
    
    if (rc < 0) {
        exit(1);
    }									// (1) fork 실패
    else if (rc == 0) {					// (2) child 인 경우 (fork 값이 0)
        printf("child (pid : %d)", (int) getpid());
    }
    else {								// (3) parent case
        printf("parent of %d (pid : %d)", rc, (int)getpid());
    }
}
```

```
pid : 29146

parent of 29147 (pid : 29146)

child (pid : 29147)
```

위와 같이 출력한다.

parent와 child의 순서는 non-deterministic(결정적이지 않음)함. 즉, 확신할 수 없음, scheduler가 결정하는 일임.

- PID
	- 프로세스 식별자, UNIX 시스템에서는 PID는 프로세스에게 명령을 할 때 사용함

Fork()가 실행되는 순간. 프로세스가 하나 더 생기는데, 이 때 생긴 프로세스(Child)는 fork를 만든 프로세스(Parent)와 (almost) 동일한 복사본을 갖게 된다.

이 때 OS는 위와 똑같은 2개의 프로그램이 동작한다고 생각하고, fork()가 return될 차례라고 생각한다.

그 때문에 새로 생성된 Process (child)는 main에서 시작하지 않고, if문부터 시작하게 된다.

그러나, 차이점이 있었다. 바로 child와 parent의 fork() 값이 다르다는 점이다. 따라서, 완전히 동일한 복사본이라 할 수 없다.

```
Parent의 fork()값 => child의 pid 값

Child의 fork()값 => 0
```

Parent와 child의 fork값이 다르다는 점은 매우 유용한 방식이다.

그러나 ! scheduler가 부모를 먼저 수행할지 아닐지 확신할 수 없다. 따라서 아래와 같이 출력될 수 있다.

```
pid : 29146

child (pid : 29147)

parent of 29147 (pid : 29146)
```

## B. wait

child 프로세스가 종료될 때까지 기다리는 작업

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/wait.h>

int main(int argc, char *argv[]) {
    printf("pid : %d", (int) getpid()); // pid : 29146
    
    int rc = fork();					// 주목
    
    if (rc < 0) {
        exit(1);
    }									// (1) fork 실패
    else if (rc == 0) {					// (2) child 인 경우 (fork 값이 0)
        printf("child (pid : %d)", (int) getpid());
    }
    else {								// (3) parent case
        int wc = wait(NULL)				// 추가된 부분
        printf("parent of %d (wc : %d / pid : %d)", wc, rc, (int)getpid());
    }
}
```

```
pid : 29146

child (pid : 29147)

parent of 29147 (wc : 29147 / pid : 29146)
```

wait를 통해서, child의 실행이 끝날때까지 기다려줌. parent가 먼저 실행되더라도, wait()는 child가 끝나기 전에는 return하지 않으므로, 반드시 child가 먼저 실행됨.

## C. exec

단순 fork는 동일한 프로세스의 내용을 여러 번 동작할 때 사용함.

child에서는 parent와 다른 동작을 하고 싶을 때는 exec를 사용할 수 있음.

```c
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/wait.h>

int main(int argc, char *argv[]) {
    printf("pid : %d", (int) getpid()); // pid : 29146
    
    int rc = fork();					// 주목
    
    if (rc < 0) {
        exit(1);
    }									// (1) fork 실패
    else if (rc == 0) {					// (2) child 인 경우 (fork 값이 0)
        printf("child (pid : %d)", (int) getpid());
        char *myargs[3];
        myargs[0] = strdup("wc");		// 내가 실행할 파일 이름
        myargs[1] = strdup("p3.c");		// 실행할 파일에 넘겨줄 argument
        myargs[2] = NULL;				// end of array
        execvp(myarges[0], myargs);		// wc 파일 실행.
        printf("this shouldn't print out") // 실행되지 않음.
    }
    else {								// (3) parent case
        int wc = wait(NULL)				// 추가된 부분
        printf("parent of %d (wc : %d / pid : %d)", wc, rc, (int)getpid());
    }
}
```

exec가 실행되면, execvp(실행 파일, 전달 인자) 함수는 code segment영역에 실행 파일의 코드를 읽어와서 덮어 씌운다.

씌운 이후에는, heap, stack, 다른 메모리 영역이 초기화되고, OS는 그냥 실행한다. 즉, 새로운 Process를 생성하지 않고, 현재 프로그램에 wc라는 파일을 생성한다. 그로인해서, execvp() 이후의 부분은 실행되지 않는다.

# 12. PCB (Process Control Block)

프로세스 메타데이터들을 저장해 놓는 곳, 한 PCB 안에는 한 프로세스의 정보가 담김

![](https://t1.daumcdn.net/cfile/tistory/25673A5058F211C224)

> 프로그램 실행 -> 프로세스 생성 -> 프로세스 주소 공간에 (코드, 데이터, 스택) 생성 -> 이 프로세스의 메타데이터들이 PCB에 저장

## A. PCB가 왜 필요한가?

CPU에서는 프로세스의 상태에 따라 교체작업이 이루어진다. (interrupt가 발생해서 할당받은 프로세스가 waiting 상태가 되고 다른 프로세스를 running으로 바꿔 올릴 때)

이때, 앞으로 다시 수행할 대기 중인 프로세스에 관한 저장 값을 PCB에 저장해두는 것이다.

## B. PCB는 어떻게 관리되는가?

Linked List 방식으로 관리된다.

PCB List Head에 PCB들이 생성될 때마다 붙게 된다. 주소값으로 연결이 이루어져 있는 연결리스트이기 때문에 삽입 삭제가 용이하다.

즉, 프로세스가 생성되면 해당 PCB가 생성되고 프로세스 완료시 제거된다.

이렇게 수행 중인 프로세스를 변경할 때, CPU의 레지스터 정보가 변경되는 것을 Context Switching이라고 한다.

# 13. IPC (Inter Process Communication)

프로세스는 다른 프로세스에게 영향을 받지 않고 독립적으로 실행된다. 이런 독립적 구조를 가진 프로세스 간의 통신을 해야 하는 상황이 있을 것이다. 이를 가능하도록 해주는 것이 IPC 통신이다.

프로세스는 커널이 제공하는 IPC 설비를 이용해 프로세스간 통신을 할 수 있게 된다.

이러한 IPC 통신에서 프로세스 간 데이터를 동기화하고 보호하기 위해 세마포어와 뮤텍스를 사용한다. (공유된 자원에 한번에 하나의 프로세스만 접근시킬 때)

## A. 커널이란?

운영체제의 핵심적인 부분으로, 다른 모든 부분에 여러 기본적인 서비스를 제공해줌

## B. IPC 종류

### a. 익명 PIPE

파이프는 두 개의 프로세스를 연결하는데 하나의 프로세스는 데이터를 쓰기만 하고, 다른 하나는 데이터를 읽기만 할 수 있다.

한쪽 방향으로만 통신이 가능한 반이중 통신이라고도 부른다.

따라서 양쪽으로 모두 송/수신을 하고 싶으면 2개의 파이프를 만들어야 한다.

매우 간단하게 사용할 수 있는 장점이 있고, 단순한 데이터 흐름을 가질 땐 파이프를 사용하는 것이 효율적이다. 단점으로는 전이중 통신을 위해 2개를 만들어야 할 때는 구현이 복잡해지게 된다.

### b. Named PIPE (FIFO)

익명 파이프는 통신할 프로세스를 명확히 알 수 있는 경우에 사용한다. (부모-자식 프로세스 간 통신처럼)

Named 파이프는 전혀 모르는 상태의 프로세스들 사이 통신에 사용한다.

즉, 익명 파이프의 확장된 상태로 부모 프로세스와 무관한 다른 프로세스도 통신이 가능한 것 (통신을 위해 이름있는 파일을 사용)

하지만, Named 파이프 역시 읽기/쓰기 동시에 불가능함. 따라서 전이중 통신을 위해서는 익명 파이프처럼 2개를 만들어야 가능

### c. Message Queue

입출력 방식은 Named 파이프와 동일함

다른점은 메시지 큐는 파이프처럼 데이터의 흐름이 아니라 메모리 공간이다.

사용할 데이터에 번호를 붙이면서 여러 프로세스가 동시에 데이터를 쉽게 다룰 수 있다.

### d. 공유 메모리

파이프, 메시지 큐가 통신을 이용한 설비라면, 공유 메모리는 데이터 자체를 공유하도록 지원하는 설비이다.

프로세스의 메모리 영역은 독립적으로 가지며 다른 프로세스가 접근하지 못하도록 반드시 보호되어야한다. 하지만 다른 프로세스가 데이터를 사용하도록 해야하는 상황도 필요할 것이다. 파이프를 이용해 통신을 통해 데이터 전달도 가능하지만, 스레드처럼 메모리를 공유하도록 해준다면 더욱 편할 것이다.

공유 메모리는 프로세스간 메모리 영역을 공유해서 사용할 수 있도록 허용해준다.

프로세스가 공유 메모리 할당을 커널에 요청하면, 커널은 해당 프로세스에 메모리 공간을 할당해주고 이후 모든 프로세스는 해당 메모리 영역에 접근할 수 있게 된다.

- 중개자 없이 곧바로 메모리에 접근할 수 있어서 IPC 중에 가장 빠르게 작동함

### e. 메모리 맵

공유 메모리처럼 메모리를 공유해준다. 메모리 맵은 열린 파일을 메모리에 맵핑시켜서 공유하는 방식이다. (공유 매개체가 파일 + 메모리)

주로 파일로 대용량 데이터를 공유해야 할 때 사용한다.

### f. 소켓

네트워크 소켓 통신을 통해 데이터를 공유한다.

클라이언트와 서버가 소켓을 통해서 통신하는 구조로, 원격에서 프로세스 간 데이터를 공유할 때 사용한다.

서버(bind, listen, accept), 클라이언트(connect)

# 14. CPU Scheduling

## A. 스케줄링

CPU를 잘 사용하기 위해 프로세스를 잘 배정하기

- 조건
	- 오버헤드 ↓ / 사용률 ↑ / 기아 현상 ↓
- 목표
	1. Batch System
		- 가능하면 많은 일을 수행.
		- 시간(time)보단 처리량(throughout)이 중요
	2. Interactive System
		- 빠른 응답 시간
		- 적은 대기 시간
	3. Real-time System
		- 기한(deadline) 맞추기

## B. 선점 / 비선점 스케줄링

- 선점 (preemptive)
	- OS가 CPU의 사용권을 선점할 수 있는 경우, 강제 회수하는 경우
- 비선점 (non-preemptive)
	- 프로세스 종료 or I/O 등의 이벤트가 있을 때까지 실행 보장 (처리시간 예측 어려움)

## C. 프로세스 상태!

[download (5)](https://user-images.githubusercontent.com/13609011/91695344-f2dfae80-eba8-11ea-9a9b-702192316170.jpeg)

- 선점 스케줄링
	- I/O or Event Wait
- 비선점 스케줄링
	- Interrupt, Scheduler Dispatch

### a. 프로세스의 상태 전이

- 승인 (Admitted)
	- 프로세스 생성이 가능하여 승인됨
- 스케줄러 디스패치 (Scheduler Dispatch)
	- 준비 상태에 있는 프로세스 중 하나를 선택하여 실행시키는 것
- 인터럽트 (Interrupt)
	- 예외, 입출력, 이벤트 등이 발생하여 현재 실행 중인 프로세스를 준비 상태로 바꾸고, 해당 작업을 먼저 처리하는 것.
- 입출력 또는 이벤트 대기 (I/O or Event wait)
	- 실행 중인 프로세스가 입출력이나 이벤트를 처리해야 하는 경우. 입출력/이벤트가 모두 끝날 때까지 대기 상태로 만드는 것
- 입출력 또는 이벤트 완료 (I/O or Event Completion)
	- 입출력/이벤트가 끝난 프로세스를 준비 상태로 전환하여 스케줄러에 의해 선택될 수 있도록 만드는 것

## D. CPU 스케줄링의 종류

### a. 선점 스케줄링

1. Priority Scheduling
	- 우선순위가 가장 높은 프로세스에 프로세서 할당
	- 우선순위가 동일한 스케줄링은 선입선처리 순서로 스케줄링 
	- Aging 방법으로 Starvation(기아) 문제 해결 가능
2. Round Robin
	- 각 프로세스는 동일한 시간의 Time Quantum 만큼 CPU를 할당받음
		- Time Quantum, Time Slice는 실행의 최소 단위 시간
	- 할당 시간(Time Quantum)이 크면 FCFS와 같게되고, 작으면 Context Switching이 잦아져서 오버헤드 증가
3. Multilevel-Queue (다단계 큐)
	- 작업들을 여러 종류의 그룹으로 나누어 여러 개의 큐를 이용하는 기법
	- 우선순위가 낮은 큐들이 실행 못하는 걸 방지하고자 각 큐마다 다른 Time Quantum을 설정해주는 방식 사용
	- 우선순위가 높은 큐는 작은 Time Quantum할당.
		- 우선순위가 낮은 큐는 큰 Time Quantum할당
4. Multilevel-Feedback-Queue (다단계 피드백 큐)
	- 다단계 큐에서 자신의 Time Quantum을 다 채운 프로세스는 밑으로 내려가고 자신의 Time Quantum을 다 채우지 못한 프로세스는 원래 큐 그대로
	- 짧은 작업에 유리, 입출력 위주(Interrupt가 잦은)작업에 우선권을 줌
	- 처리 시간이 짧은 프로세스를 먼저 처리하기 때문에 Turnaround 평균 시간을 줄여줌
5. SRT (Shortest Remaining Time) 선점 최소작업 우선 스케줄링
	- 최소작업 우선 스케줄링(SJF)에 선점 스케줄링을 적용한 것

### b. 비선점 스케줄링

1. FCFS (First Come First Served)
	- 큐에 도착한 순서대로 CPU 할당
	- 실행 시간이 짧은게 뒤로 가면 평균 대기 시간이 길어짐
2. SJF (Shortest Job First) 최소작업 우선 스케줄링
	- 수행시간이 가장 짧다고 판단되는 작업을 먼저 수행
	- FCFS보다 평균 대기 시간 감소, 짧은 작업에 유리
3. HRN (Highest Response-ratio Next)
	- 우선순위를 계산하여 점유 불평등을 보완한 방법 (SJF의 단점 보완)
	- 우선순위 = (대기시간 + 실행시간) / (실행시간)

## E. CPU 스케줄링 척도

1. Response Time
	- 작업이 처음 실행되기까지 걸린 시간
2. Turnaround Time
	- 실행 시간과 대기 시간을 모두 합한 시간으로 작업이 완료될 때까지 걸린 시간

# 14. 경쟁 상태 (Race Condition)

공유 자원에 대해 여러 프로세스가 동시에 접근할 대, 결과값에 영향을 줄 수 있는 상태

> 동시 접근 시 자료의 일관성을 해치는 결과가 나타남

## A. Race Condition이 발생하는 경우

1. 커널 작업을 수행하는 중에 인터럽트 발생
	- 문제점
		- 커널모드에서 데이터를 로드하여 작업을 수행하다가 인터럽트가 발생하여 같은 데이터를 조작하는 경우
	- 해결법
		- 커널모드에서 작업을 수행하는 동안, 인터럽트를 disable 시켜 CPU 제어권을 가져가지 못하도록 한다.
2. 프로세스가 **System Call**을 하여 커널 모드로 진입하여 작업을 수행하는 도중 문맥 교환이 발생할 때
	- 문제점
		- 프로세스1이 커널 모드에서 데이터를 조작하는 도중, 시간이 초과되어 CPU 제어권이 프로세스2로 넘어가 같은 데이터를 조작하는 경우 (프로세스 2가 작업에 반영되지 않음)
	- 해결법
		- 프로세스가 커널모드에서 작업을 하는 경우 시간이 초과되어도 CPU 제어권이 다른 프로세스에게 넘어가지 않도록 함
3. 멀티 프로세서 환경에서 공유 메모리 내의 커널 데이터에 접근할 때
	- 문제점
		- 멀티 프로세서 환경에서 2개의 CPU가 동시에 커널 내부의 공유 데이터에 접근하여 조작하는 경우
	- 해결법
		- 커널 내부에 있는 각 공유 데이터에 접근할 때마다, 그 데이터에 대한 lock/unlock을 하는 방법